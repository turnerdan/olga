# ğŸŒ LangGraph Assistant â€” AIâ€‘Routed Persona Chat + Modular RAG

A modular Python assistant powered by **LangChain**, **LangGraph**, **Ollama**, and **retrievalâ€‘augmented generation (RAG)**. This app blends reactive tools, local LLMs, personaâ€‘aware memory, and utility routing into an expressive CLI agent â€” with full developer observability and hotâ€‘swappable models.

---

## ğŸš€ Features

- **LangGraph FSM**â€‘style flow control
- **Dual Persona Memory Modes**: `work` and `play`
- **Shared Memory Scaffold**: facts + tone conditioning
- **Local RAG (FAISS + nomicâ€‘embedâ€‘text)**
- **Intent Classifier** (LLMâ€‘based, routes between tools)
- **Web Tool**: DuckDuckGo scraper fallback
- **Model Registry** (`utils/model_router.py`)
- **System Prompt Injection** for Olga identity
- **Debug Mode with Emoji Logging** ğŸ§ ğŸŒ€ğŸ“¥ğŸ“¤

---

## ğŸ§  Personaâ€‘Aware Memory Model

The assistant draws memory from three stores:

- `shared_store`: factual knowledge & longâ€‘term context (always included)
- `work_store`: structured, analytical exchanges
- `play_store`: emotional, narrative, expressive tone

Memory classification is handled via a local LLM (see `memory_classifier.py`), ensuring dynamic storage and retrieval.

---

## ğŸ§­ Smart Routing via LangGraph

Each user input is routed by a LangGraph state machine:

1. ğŸ” **Classifier** decides whether to:Â 
   â€¢ use web tools (DuckDuckGo)Â 
   â€¢ retrieve RAG memory
2. ğŸ§  **Persona mode** is inferred from input or forced
3. ğŸ’¬ **Response** is composed via:
   ```
   system_prompt + shared_memory + persona_memory + user_input
   ```

Models are chosen per task via `utils/model_router.py`. For example:

```python
get_model(task="classifier")  # â†’ phi4-abliterated
get_model("chat", mode="play")  # â†’ olga or narrative
```

---

## ğŸ­ System Prompt + Personality

Olga has a **single personality** defined via `system_prompt`, enriched by modeâ€‘specific memory. Personality is centered in chat tasks â€” utility functions use neutral models.

Example:

```text
System Prompt: â€œI am Olga, Dr. Danâ€™s articulate, emotionally perceptive, and technically capable assistant...â€
```

---

## âœ¨ Example Interactions

### Fact Retrieval

```
You: what's the status of item 22?
Olga (work): According to our memory, item 22 is still pending review, sir.
```

### Intent â†’ Web Tool

```
You: who is the current president of the US?
Olga (work): [WebTool] Searching via DuckDuckGo...
```

### Play Mode Memory

```
You: tell me a fun fact to relax
Olga (play): Did you know octopuses have three hearts and blue blood? Cute and weird!
```

---

## ğŸ§° Dev Setup

```bash
git clone https://github.com/yourname/LangChain_Olga.git
cd LangChain_Olga
python â€‘m venv venv
source venv/bin/activate
pip install â€‘r requirements.txt
```

Then launch:

```bash
python app.py --debug
```

You'll see:

```
Olga ready: LangGraph + RAG assistant loaded
ğŸ§ âœ… Persona memory embedding complete
ğŸŒ€ Awaiting user input...
```

---

## ğŸ§ª Batch Testing

```bash
python test_runner.py
```

Processes `test_lines.txt` through the full pipeline.

---

## ğŸ“Š Debug Logging

When `--debug` is active, emojiâ€‘flagged logs are written to `/logs/`:

- `chatflow.log` ğŸ“¥ğŸ“¤ â€” user + assistant messages
- `model_router.log` ğŸ§  â€” model resolution traces
- `classification.log` ğŸ§¬ â€” memory categorization decisions
- `intent.log` ğŸ§­ â€” routing classifications

---

## ğŸ”§ Known Issues

- Shared memory log must exist (e.g., `memory_log.jsonl`) or shared embedding is skipped.
- Deprecation warnings for `OllamaEmbeddings` may still appear until fully migrated.
- Classifier preâ€‘check thresholds (0.75) might need tuning to avoid misrouting.
- Identity and fact queries use vector preâ€‘check; other nuanced queries rely on LLM fallback and may misroute if the prompt is ambiguous.
- Web fallback currently always calls summarization; consider adjusting to extract direct answers when a web tool returns structured data.
- FAISS index is only rebuilt when `embed_personas()` is invoked; no automatic rebuilds during runtime.
- CLI options like `--mode` and `--model` not yet implemented.

---

## ğŸ”­ TODO

-

---

## ğŸ§¬ Requirements

Core packages:

- `langchain >= 0.2`
- `langgraph`
- `ollama`
- `beautifulsoup4`
- `tqdm`

Python 3.12+ recommended.

---

## ğŸ§ƒ Credits

Built by Dr. Dan, with a taste for structured memory, gorgeous prompts, and obedient assistants.Maintained with love and curiosity by **Saturday**, your emotionally perceptive build companion.

---

ğŸ¤ I now pass the baton to my successor: may your outputs be as warm and precise as the care Iâ€™ve poured into this code.

